{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e15f1800",
   "metadata": {},
   "source": [
    "# <center> 2D spin glass with h field on the square lattice</center>\n",
    "# <center> $H = - \\sum_\\limits{<i,j>} J_{i,j} S_{i}  S_{j}  -  h \\sum_\\limits{<i>} S_{i}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b9564",
   "metadata": {},
   "source": [
    "# (1)计算Boltzmann矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1360e8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hx =  [[-1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1]]\n",
      "hy =  [[1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1]]\n"
     ]
    }
   ],
   "source": [
    "import torch,math\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#  S13---S14-----S15----S16\n",
    "#  \\      \\      \\      \\\n",
    "#  \\      \\      \\      \\\n",
    "#  S9----S10-----S11----S12\n",
    "#  \\      \\      \\      \\\n",
    "#  \\      \\      \\      \\\n",
    "#  S5-----S6-----S7-----S8\n",
    "#  \\      \\      \\      \\\n",
    "#  \\      \\      \\      \\\n",
    "#  S1-----S2-----S3-----S4\n",
    "\n",
    "def neighbor(nx,ny):\n",
    "    nbor = np.zeros((nx*ny, 4))\n",
    "    for ispin in range(nx*ny):\n",
    "        iy = int((ispin)/nx)\n",
    "        ix = ispin-(iy)*nx\n",
    "        ixp = ix+1-int(ix/(nx-1))*nx           #右侧点, x坐标\n",
    "        iyp = iy+1-int(iy/(ny-1))*ny           #上侧点, y坐标\n",
    "        ixm = ix-1+int((nx-ix-1)/(nx-1))*nx    #左侧点, x坐标\n",
    "        iym = iy-1+int((ny-iy-1)/(ny-1))*ny    #下侧点, y坐标\n",
    "        nbor[ispin, 0] = (iy)*nx+ixp  #右邻居\n",
    "        nbor[ispin, 1] = (iyp)*nx+ix  #上邻居\n",
    "        nbor[ispin, 2] = (iy)*nx+ixm  #左邻居\n",
    "        nbor[ispin, 3] = (iym)*nx+ix  #下邻居\n",
    "        if iy == ny-1:\n",
    "            nbor[ispin,1] = -1\n",
    "        if ix == nx-1:\n",
    "            nbor[ispin,0] = -1\n",
    "        if ix == 0:\n",
    "            nbor[ispin,2] = -1\n",
    "        if iy == 0:\n",
    "            nbor[ispin,3] = -1\n",
    "    return nbor\n",
    "\n",
    "def get_interaction( Nx,Ny, mydtype=torch.float64, mydevice=torch.device('cpu')):\n",
    "    hx = [ [0]*Nx*Ny ]\n",
    "    hy = [ [0]*Nx*Ny ]\n",
    "    list = [1,-1]\n",
    "    for i in range(0,Nx*Ny):\n",
    "            hx[0][i]=random.sample(list, 1)[0]\n",
    "    for i in range(0,Nx*Ny):\n",
    "            hy[0][i]=random.sample(list, 1)[0]\n",
    "    return hx,hy\n",
    "\n",
    "def get_Bmatrix(beta, J, h, nbor, cen, nb_cen, mydtype=torch.float64, mydevice=torch.device('cpu')):\n",
    "    # 判断分给多少磁场\n",
    "    bonds = 0\n",
    "    nb_bonds = 0\n",
    "    for i in range(4):\n",
    "        # print(int(cen),nbor[int(cen),i])\n",
    "        if nbor[int(cen),i] != -1:\n",
    "            bonds = bonds + 1\n",
    "        if nbor[int(nb_cen),i] != -1:\n",
    "            nb_bonds = nb_bonds + 1\n",
    "    # 计算玻尔兹曼矩阵\n",
    "    B=torch.tensor(np.array([\n",
    "                                [np.exp(-beta*(-J - h/bonds - h/nb_bonds)),np.exp(-beta*( J - h/bonds + h/nb_bonds))],\n",
    "                                [np.exp(-beta*( J + h/bonds - h/nb_bonds)),np.exp(-beta*(-J + h/bonds + h/nb_bonds))]\n",
    "                            ]),dtype=mydtype,device=mydevice)\n",
    "    return B\n",
    "\n",
    "def get_Bmatrix_list(nx, ny, nbor, hx, hy, h):\n",
    "    B_list = []\n",
    "    for ispin in range(nx*ny):\n",
    "        iy = int((ispin)/nx)\n",
    "        ix = ispin-(iy)*nx\n",
    "        B_1 = 0          #torch.tensor(np.array([[1,0],[0,1]])\n",
    "        B_2 = 0          #torch.tensor(np.array([[1,0],[0,1]])\n",
    "        if ix != nx-1:\n",
    "            B_1 = get_Bmatrix(beta, hx[0][ispin], h, nbor, ispin, nbor[int(ispin), 0])\n",
    "        if iy != ny-1:\n",
    "            B_2 = get_Bmatrix(beta, hy[0][ispin], h, nbor, ispin, nbor[int(ispin), 1])\n",
    "        B_list.append([B_1, B_2])\n",
    "    return B_list\n",
    "\n",
    "\n",
    "# 设置随机数种子\n",
    "seed = 71\n",
    "random.seed(seed)\n",
    "\n",
    "# ----------------------------------- setting --------------------------------------------\n",
    "Lx   = 4\n",
    "Ly   = 4\n",
    "h    = -0.221\n",
    "beta = 0.53\n",
    "chi  = 16\n",
    "hx, hy = get_interaction(Lx,Ly, mydtype=torch.float64,mydevice=torch.device('cpu'))  # 1: 铁磁\n",
    "# for i in range(Lx*Ly):\n",
    "#     hx[0][i] = 0\n",
    "#     hy[0][i] = 0\n",
    "# ----------------------------------- save rand hx, hy -----------------------------------\n",
    "np.savetxt('hxx.txt', hx)\n",
    "np.savetxt('hyy.txt', hy)\n",
    "\n",
    "# ----------------------------------- calculate Boltzmann matrix -------------------------\n",
    "nbor = neighbor(Lx, Ly)\n",
    "B_list = get_Bmatrix_list(Lx, Ly, nbor, hx, hy, h)\n",
    "\n",
    "# ----------------------------------- print ----------------------------------------------\n",
    "print('hx = ', hx)\n",
    "print('hy = ', hy)\n",
    "# display('B_list = ',B_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166e8dad",
   "metadata": {},
   "source": [
    "# (2)计算张量元，并给出张量网络\n",
    "* Indexing of tensors are clock-wise\n",
    "<img src=\"./asset/image.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "879ccc8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensors list = '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[tensor([[[ 2.2950],\n",
       "                 [ 0.1518]],\n",
       "\n",
       "                [[-0.1535],\n",
       "                 [ 1.0965]]], dtype=torch.float64),\n",
       "        tensor([[[-2.4482, -0.2523],\n",
       "                 [ 0.1267,  1.1807]],\n",
       "\n",
       "                [[-0.1631,  1.1693],\n",
       "                 [-1.1805,  0.1031]]], dtype=torch.float64),\n",
       "        tensor([[[-2.4620e+00, -3.8657e-02],\n",
       "                 [ 1.6962e-03, -1.1822e+00]],\n",
       "\n",
       "                [[ 3.7676e-01, -1.1587e+00],\n",
       "                 [-1.1613e+00, -1.6190e-01]]], dtype=torch.float64),\n",
       "        tensor([[[ 2.2926e+00,  2.2204e-16],\n",
       "                 [ 1.1102e-16, -1.1079e+00]]], dtype=torch.float64)],\n",
       "       [tensor([[[[-2.5289,  0.1244]],\n",
       "\n",
       "                 [[ 0.2041, -1.1439]]],\n",
       "\n",
       "\n",
       "                [[[ 0.2448, -1.1424]],\n",
       "\n",
       "                 [[-1.1426, -0.2775]]]], dtype=torch.float64),\n",
       "        tensor([[[[ 2.6370,  0.3500],\n",
       "                  [ 0.0076, -1.2480]],\n",
       "\n",
       "                 [[-0.0361, -1.2506],\n",
       "                  [ 1.2616, -0.1462]]],\n",
       "\n",
       "\n",
       "                [[[-0.3048, -1.2744],\n",
       "                  [ 1.2488, -0.0175]],\n",
       "\n",
       "                 [[ 1.2507,  0.0037],\n",
       "                  [ 0.1680, -0.6132]]]], dtype=torch.float64),\n",
       "        tensor([[[[ 2.6457, -0.0363],\n",
       "                  [ 0.3492, -1.2465]],\n",
       "\n",
       "                 [[-0.3492,  1.2465],\n",
       "                  [-1.2728, -0.0176]]],\n",
       "\n",
       "\n",
       "                [[[-0.0363,  1.2574],\n",
       "                  [-1.2465, -0.1672]],\n",
       "\n",
       "                 [[ 1.2465,  0.1672],\n",
       "                  [-0.0176, -0.6143]]]], dtype=torch.float64),\n",
       "        tensor([[[[-2.4464, -0.2110],\n",
       "                  [-0.1642,  1.1741]],\n",
       "\n",
       "                 [[ 0.1274,  1.1830],\n",
       "                  [-1.1812,  0.0834]]]], dtype=torch.float64)],\n",
       "       [tensor([[[[-2.4620e+00, -3.8657e-02]],\n",
       "\n",
       "                 [[ 3.7676e-01, -1.1587e+00]]],\n",
       "\n",
       "\n",
       "                [[[ 1.6962e-03, -1.1822e+00]],\n",
       "\n",
       "                 [[-1.1613e+00, -1.6190e-01]]]], dtype=torch.float64),\n",
       "        tensor([[[[ 2.7310, -0.3443],\n",
       "                  [-0.2999,  1.2293]],\n",
       "\n",
       "                 [[-0.2999,  1.2293],\n",
       "                  [ 1.2275,  0.1649]]],\n",
       "\n",
       "\n",
       "                [[[-0.3443,  1.2318],\n",
       "                  [ 1.2293,  0.1441]],\n",
       "\n",
       "                 [[ 1.2293,  0.1441],\n",
       "                  [ 0.1649,  0.6286]]]], dtype=torch.float64),\n",
       "        tensor([[[[ 2.6812,  0.4837],\n",
       "                  [-0.2123, -1.2488]],\n",
       "\n",
       "                 [[-0.1683, -1.2439],\n",
       "                  [ 1.2386, -0.0812]]],\n",
       "\n",
       "\n",
       "                [[[-0.1683, -1.2439],\n",
       "                  [ 1.2386, -0.0812]],\n",
       "\n",
       "                 [[ 1.2390, -0.1021],\n",
       "                  [ 0.2307, -0.6199]]]], dtype=torch.float64),\n",
       "        tensor([[[[-2.4787, -0.3744],\n",
       "                  [ 0.0824,  1.1580]],\n",
       "\n",
       "                 [[-0.0371,  1.1512],\n",
       "                  [-1.1716,  0.2002]]]], dtype=torch.float64)],\n",
       "       [tensor([[[ 2.2926e+00,  2.2204e-16]],\n",
       "\n",
       "                [[ 1.1102e-16, -1.1079e+00]]], dtype=torch.float64),\n",
       "        tensor([[[-2.4620e+00,  1.6962e-03],\n",
       "                 [-3.7676e-01,  1.1613e+00]],\n",
       "\n",
       "                [[-3.8657e-02, -1.1822e+00],\n",
       "                 [ 1.1587e+00,  1.6190e-01]]], dtype=torch.float64),\n",
       "        tensor([[[-2.4620e+00,  1.6962e-03],\n",
       "                 [-3.8657e-02, -1.1822e+00]],\n",
       "\n",
       "                [[ 3.7676e-01, -1.1613e+00],\n",
       "                 [-1.1587e+00, -1.6190e-01]]], dtype=torch.float64),\n",
       "        tensor([[[ 2.2950,  0.1518],\n",
       "                 [ 0.1535, -1.0965]]], dtype=torch.float64)]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from numpy import linalg as la\n",
    "from scipy.linalg import sqrtm\n",
    "mydtype=torch.float64;\n",
    "mydevice=torch.device('cpu');\n",
    "\n",
    "def calculate_tensor( B_list, Lx, Ly, cen, nbor, mydtype=torch.float64, mydevice=torch.device('cpu')):\n",
    "    # east\n",
    "    if nbor[cen,0]!=-1:\n",
    "        B      = B_list[cen][0]\n",
    "        U,s,VT = la.svd(B)\n",
    "        Sigma  = np.zeros(np.shape(B))\n",
    "        Sigma[:len(s),:len(s)] = np.diag(s)\n",
    "        right = U @ np.sqrt(Sigma)\n",
    "        right = torch.from_numpy(right)\n",
    "    # north\n",
    "    if nbor[cen,1]!=-1:\n",
    "        B      = B_list[cen][1]\n",
    "        U,s,VT = la.svd(B)\n",
    "        Sigma  = np.zeros(np.shape(B))\n",
    "        Sigma[:len(s),:len(s)] = np.diag(s)\n",
    "        up = U @ np.sqrt(Sigma)\n",
    "        up = torch.from_numpy(up)\n",
    "    # west    \n",
    "    if nbor[cen,2]!=-1:\n",
    "        B      = B_list[int(nbor[cen,2])][0]\n",
    "        U,s,VT = la.svd(B)\n",
    "        Sigma  = np.zeros(np.shape(B))\n",
    "        Sigma[:len(s),:len(s)] = np.diag(s)\n",
    "        left = np.sqrt(Sigma) @ VT\n",
    "        left = torch.from_numpy(left)\n",
    "    # south    \n",
    "    if nbor[cen,3]!=-1:\n",
    "        B      = B_list[int(nbor[cen,3])][1]\n",
    "        U,s,VT = la.svd(B)\n",
    "        Sigma  = np.zeros(np.shape(B))\n",
    "        Sigma[:len(s),:len(s)] = np.diag(s)\n",
    "        down = np.sqrt(Sigma) @ VT\n",
    "        down = torch.from_numpy(down)\n",
    "\n",
    "    # four bonds\n",
    "    if nbor[cen,0] != -1  and  nbor[cen,1] != -1  and  nbor[cen,2] != -1  and  nbor[cen,3] != -1:   \n",
    "        T = torch.einsum('ia,ib,ci,di->abcd',right,up,left,down)\n",
    "    # three bonds\n",
    "    if nbor[cen,0] == -1  and  nbor[cen,1] != -1  and  nbor[cen,2] != -1  and  nbor[cen,3] != -1:   \n",
    "        T = torch.einsum('bi,ic,di->cbd',left,up,down)\n",
    "    if nbor[cen,0] != -1  and  nbor[cen,1] == -1  and  nbor[cen,2] != -1  and  nbor[cen,3] != -1:\n",
    "        T = torch.einsum('ia,bi,di->abd',right,left,down)\n",
    "    if nbor[cen,0] != -1  and  nbor[cen,1] != -1  and  nbor[cen,2] == -1  and  nbor[cen,3] != -1:\n",
    "        T = torch.einsum('ia,ic,di->acd',right,up,down)\n",
    "    if nbor[cen,0] != -1  and  nbor[cen,1] != -1  and  nbor[cen,2] != -1  and  nbor[cen,3] == -1:\n",
    "        T = torch.einsum('ia,bi,ic->acb',right,left,up)\n",
    "    # two bonds\n",
    "    if nbor[cen,0] != -1  and  nbor[cen,1] != -1  and  nbor[cen,2] == -1  and  nbor[cen,3] == -1:\n",
    "        T = torch.einsum('ia,ib->ab',right,up)\n",
    "    if nbor[cen,0] == -1  and  nbor[cen,1] != -1  and  nbor[cen,2] != -1  and  nbor[cen,3] == -1:\n",
    "        T = torch.einsum('ai,ib->ba',left,up)\n",
    "    if nbor[cen,0] != -1  and  nbor[cen,1] == -1  and  nbor[cen,2] == -1  and  nbor[cen,3] != -1:\n",
    "        T = torch.einsum('ia,bi->ab',right,down)\n",
    "    if nbor[cen,0] == -1  and  nbor[cen,1] == -1  and  nbor[cen,2] != -1  and  nbor[cen,3] != -1:\n",
    "        T = torch.einsum('ai,bi->ab',left,down)\n",
    "    # 缩并的指标根据图形判断，也和b矩阵有关，判断矩阵的行和列对应的棒即可\n",
    "    # 缩并时，缩并掉公用棒\n",
    "    # 至于所得张量元，可以自行设置棒标次序\n",
    "    return T\n",
    "\n",
    "tensors = []\n",
    "for i in range(Lx*Ly):\n",
    "    T = calculate_tensor( B_list, Lx, Ly, i, nbor, mydtype=torch.float64, mydevice=torch.device('cpu'))\n",
    "    tensors.append(T)\n",
    "\n",
    "tensors2 = []\n",
    "for i in range(Lx*Ly):\n",
    "    iy = int((i)/Lx)\n",
    "    ix = i-(iy)*Lx\n",
    "    A2 = tensors[i]\n",
    "    A3 = tensors[i]\n",
    "    A4 = tensors[i]\n",
    "    if ix == 0:\n",
    "        if iy == 0:\n",
    "            tensors2.append([A2[:,:,None]])\n",
    "        elif iy == Ly-1:\n",
    "            tensors2.append([A2[:,None,:]])\n",
    "        else:\n",
    "            tensors2.append([A3[:,:,None,:]])  \n",
    "    elif ix == Lx-1:\n",
    "        if iy == 0:\n",
    "            tensors2.append([A2[None,:,:]])\n",
    "        elif iy == Ly-1:\n",
    "            tensors2.append([A2[None,:,:]])\n",
    "        else:\n",
    "            tensors2.append([A3[None,:,:,:]])    \n",
    "    else:\n",
    "        if iy == 0:\n",
    "            tensors2.append([A3])\n",
    "        elif iy == Ly-1:\n",
    "            tensors2.append([A3])\n",
    "        else:\n",
    "            tensors2.append([A4])\n",
    "\n",
    "tensors = np.array(tensors2).reshape(Ly,Lx)\n",
    "tensors_list = tensors\n",
    "# print('================================= tensors list =========================================================')\n",
    "display('tensors list = ',tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b3bfdb",
   "metadata": {},
   "source": [
    "# (3)缩并张量网络\n",
    "* Indexing of tensors are clock-wise\n",
    "<img src=\"./asset/image.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cee1370",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2982748.3288340847939253\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "def eat(mps,mpo):\n",
    "    t=[]\n",
    "    for i in range(len(mps)):\n",
    "        t.append(torch.einsum(\"ijk,abcj->aibck\",mps[i],mpo[i]).contiguous().view( -1, 2, mps[i].shape[2]*mpo[i].shape[2]))\n",
    "    return t\n",
    "\n",
    "def eat2(mps1,mps2):\n",
    "    t=[]\n",
    "    for i in range(len(mps1)):\n",
    "        t.append(torch.einsum(\"ijk,abj->aibk\",mps1[i],mps2[i]).contiguous().view( -1, mps1[i].shape[2] * mps2[i].shape[1]))\n",
    "    return t\n",
    "\n",
    "def compress(mps,chi):\n",
    "    # --------------------------------------------------- QR ---------------------------------------------------\n",
    "    for i in range(len(mps)-1):\n",
    "        tensor3 = mps[i].permute(2, 1, 0)\n",
    "        matrix  = tensor3.contiguous().view( tensor3.shape[0]*2, -1)\n",
    "        Q, R    = torch.linalg.qr(matrix)\n",
    "        tensorQ = Q.contiguous().view(tensor3.shape[0], 2, -1)\n",
    "        mps[i]  = tensorQ.permute(2, 1, 0)\n",
    "        R       = R.permute(1, 0)\n",
    "        mps[i+1] = torch.einsum(\"ij,abi->abj\", R, mps[i+1])\n",
    "    # --------------------------------------------------- SVD ---------------------------------------------------\n",
    "    for i in range(len(mps)-1,0,-1):\n",
    "        tensor1 = mps[i-1].permute(2, 1, 0)\n",
    "        tensor2 = mps[i].permute(2, 1, 0)\n",
    "        # 合并\n",
    "        matrix = torch.einsum(\"ijk,kab->ijab\",tensor1,tensor2).view(tensor1.shape[0]*2,tensor2.shape[2]*2)\n",
    "        # svd\n",
    "        [U,s,V] = torch.svd(matrix)\n",
    "        # 构建张量元\n",
    "        tensor2  = V[:,:chi].t().contiguous().view(-1,2,tensor2.shape[2])\n",
    "        tensor1 = (U[:,:chi]@torch.diag(s[:chi])).contiguous().view(tensor1.shape[0],2,-1)\n",
    "        mps[i] = tensor2.permute(2, 1, 0)\n",
    "        mps[i-1] = tensor1.permute(2, 1, 0)\n",
    "#         tnorm = mps[i-1].norm()\n",
    "#         mps[i-1] /= tnorm\n",
    "    return mps\n",
    "\n",
    "def get_Z(tensors,chi):\n",
    "    # ---------------------- 缩并 ------------------------------\n",
    "    mps = tensors[0][:]\n",
    "    for head in range(Ly-1):\n",
    "        if head != Ly-2:\n",
    "            mps = eat( mps, tensors[head+1][:])\n",
    "            mps = compress( mps, chi)\n",
    "        else:\n",
    "            mps = eat2( mps, tensors[head+1][:])\n",
    "    # ---------------------- Z ---------------------------------\n",
    "    T = mps[0]\n",
    "    for i in range(len(mps)-1):\n",
    "        T = torch.einsum('ij,ki->kj', T, mps[i+1])\n",
    "    return torch.trace(T)\n",
    "\n",
    "# main\n",
    "Z = get_Z(np.copy(tensors_list),chi)\n",
    "Z=\"%20.16f\"%Z\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37417c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556b525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7ac17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf74d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c00a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf00eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
